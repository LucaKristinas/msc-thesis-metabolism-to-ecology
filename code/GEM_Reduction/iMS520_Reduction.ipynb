{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Standard Library and 3rd Party Imports \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy\n",
    "import copy\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import chain, combinations\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COBRA imports\n",
    "\n",
    "import cobra\n",
    "from cobra import Model, Reaction\n",
    "from cobra.core import Group, Reaction\n",
    "from cobra.flux_analysis import flux_variability_analysis\n",
    "from cobra.flux_analysis.fastcc import fastcc\n",
    "from cobra.io import read_sbml_model, save_matlab_model, write_sbml_model\n",
    "from cobra.util.solver import linear_reaction_coefficients\n",
    "from rapidfuzz import fuzz, process\n",
    "from cobra.util.array import create_stoichiometric_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lump_reaction(model, coupled_df, verbose=True, Search_COBRA_groups=False, label_type=\"Group\"):\n",
    "    \"\"\"\n",
    "    Create a lumped model by replacing fully coupled reaction groups with pseudo-reactions.\n",
    "\n",
    "    Parameters:\n",
    "    - model: cobra.Model (the original model, will remain unchanged)\n",
    "    - coupled_df: pd.DataFrame with either:\n",
    "        - columns ['Coupled_Reactions', 'COBRA_Groups'] (default format), or\n",
    "        - column ['Reactions'], and Search_COBRA_groups=True\n",
    "    - verbose: bool, if True print progress messages\n",
    "    - Search_COBRA_groups: bool, if True, search model groups for each reaction if not supplied\n",
    "    - label_type: str, either 'Group' or 'Module' — used in pseudo-reaction naming (required)\n",
    "\n",
    "    Returns:\n",
    "    - model_lumped: cobra.Model with pseudo-reactions added\n",
    "    - translation_df: pd.DataFrame mapping pseudo-reactions to original reactions and groups\n",
    "    \"\"\"\n",
    "    import copy\n",
    "    from cobra import Reaction\n",
    "    from collections import defaultdict\n",
    "    import pandas as pd\n",
    "\n",
    "    model_lumped = copy.deepcopy(model)\n",
    "    translation_data = []\n",
    "\n",
    "    # Handle case with only 'Reactions' column — determine COBRA_Groups if needed\n",
    "    if Search_COBRA_groups and 'Reactions' in coupled_df.columns:\n",
    "        cobra_groups_list = []\n",
    "        for i, row in coupled_df.iterrows():\n",
    "            reaction_list = row['Reactions']\n",
    "            found_groups = set()\n",
    "            for rxn_id in reaction_list:\n",
    "                for group in model.groups:\n",
    "                    if rxn_id in [rxn.id for rxn in group.members]:\n",
    "                        found_groups.add(group.name)\n",
    "            cobra_groups_list.append(list(found_groups))\n",
    "        coupled_df = coupled_df.rename(columns={'Reactions': 'Coupled_Reactions'})\n",
    "        coupled_df['COBRA_Groups'] = cobra_groups_list\n",
    "\n",
    "    for i, row in coupled_df.iterrows():\n",
    "        group_reactions = row['Coupled_Reactions']\n",
    "        cobra_groups = row['COBRA_Groups']\n",
    "\n",
    "        valid_reactions = []\n",
    "        for rxn_id in group_reactions:\n",
    "            if rxn_id in model_lumped.reactions:\n",
    "                valid_reactions.append(rxn_id)\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"⚠️ Reaction '{rxn_id}' not found in model — skipping.\")\n",
    "\n",
    "        if len(valid_reactions) < 2:\n",
    "            if verbose:\n",
    "                print(f\"⏭️ Skipping group {i} — fewer than 2 valid reactions.\")\n",
    "            continue\n",
    "\n",
    "        lower_bounds = []\n",
    "        upper_bounds = []\n",
    "        for rxn_id in valid_reactions:\n",
    "            rxn = model_lumped.reactions.get_by_id(rxn_id)\n",
    "            lower_bounds.append(rxn.lower_bound)\n",
    "            upper_bounds.append(rxn.upper_bound)\n",
    "        min_lb = max(lower_bounds)\n",
    "        max_ub = min(upper_bounds)\n",
    "\n",
    "        net_stoich = defaultdict(float)\n",
    "        for rxn_id in valid_reactions:\n",
    "            rxn = model_lumped.reactions.get_by_id(rxn_id)\n",
    "            for met, coeff in rxn.metabolites.items():\n",
    "                net_stoich[met] += coeff\n",
    "\n",
    "        cleaned_stoich = {met: coeff for met, coeff in net_stoich.items() if abs(coeff) > 1e-10}\n",
    "\n",
    "        pseudo_id = f\"Pseudo_{label_type}_{i}\"\n",
    "        pseudo_rxn = Reaction(id=pseudo_id)\n",
    "        pseudo_rxn.name = f\"Lumped reaction for: {', '.join(valid_reactions)}\"\n",
    "        pseudo_rxn.lower_bound = min_lb\n",
    "        pseudo_rxn.upper_bound = max_ub\n",
    "        pseudo_rxn.add_metabolites(cleaned_stoich)\n",
    "\n",
    "        model_lumped.add_reactions([pseudo_rxn])\n",
    "\n",
    "        for group in model_lumped.groups:\n",
    "            if group.name in cobra_groups:\n",
    "                group.add_members([pseudo_rxn])\n",
    "\n",
    "        for rxn_id in valid_reactions:\n",
    "            rxn = model_lumped.reactions.get_by_id(rxn_id)\n",
    "            for group in model_lumped.groups:\n",
    "                if rxn in group.members:\n",
    "                    group.members.remove(rxn)\n",
    "            model_lumped.reactions.remove(rxn)\n",
    "\n",
    "        translation_data.append({\n",
    "            'Pseudo_Reaction_ID': pseudo_id,\n",
    "            'Original_Reactions': valid_reactions,\n",
    "            'COBRA_Groups': cobra_groups\n",
    "        })\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"✅ {label_type} {i}: Created '{pseudo_id}' from {valid_reactions}\")\n",
    "\n",
    "    translation_df = pd.DataFrame(translation_data)\n",
    "    return model_lumped, translation_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_reactions_interconnected(model, reaction_ids):\n",
    "    \"\"\"\n",
    "    Check whether a list of reactions are all interconnected via shared metabolites.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: cobra.Model\n",
    "    - reaction_ids: list of reaction IDs to test\n",
    "\n",
    "    Returns:\n",
    "    - bool: True if all reactions are connected via shared metabolites\n",
    "    \"\"\"\n",
    "    # Create a graph where nodes = reactions, edges = shared metabolite\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(reaction_ids)\n",
    "\n",
    "    # Build edges based on shared metabolites\n",
    "    for i, rxn1_id in enumerate(reaction_ids):\n",
    "        if rxn1_id not in model.reactions:\n",
    "            continue\n",
    "        rxn1 = model.reactions.get_by_id(rxn1_id)\n",
    "        mets1 = set(rxn1.metabolites)\n",
    "\n",
    "        for rxn2_id in reaction_ids[i+1:]:\n",
    "            if rxn2_id not in model.reactions:\n",
    "                continue\n",
    "            rxn2 = model.reactions.get_by_id(rxn2_id)\n",
    "            mets2 = set(rxn2.metabolites)\n",
    "\n",
    "            # Add edge if they share at least one metabolite\n",
    "            if mets1 & mets2:\n",
    "                G.add_edge(rxn1_id, rxn2_id)\n",
    "\n",
    "    # Check if the graph is fully connected\n",
    "    return nx.is_connected(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_model(model, model_name, carb_list):\n",
    "    \"\"\"\n",
    "    Run FBA simulations for a COBRA model across multiple carbon source conditions.\n",
    "\n",
    "    For each carbon source in the provided list, this function:\n",
    "    - Allows uptake only for that carbon source (by setting its flux bounds).\n",
    "    - Blocks all other carbon sources.\n",
    "    - Runs Flux Balance Analysis (FBA).\n",
    "    - Records which reactions are active (i.e., carry non-zero flux).\n",
    "    - Stores the model's objective value (e.g., growth rate).\n",
    "\n",
    "    The function returns:\n",
    "    1. A summary DataFrame with objective values for each carbon source.\n",
    "    2. A full flux activity matrix (True/False for each reaction in each condition).\n",
    "    3. A filtered version of the matrix showing only reactions that are active in some but not all conditions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : cobra.Model\n",
    "        The COBRA model to simulate.\n",
    "\n",
    "    model_name : str\n",
    "        Identifier for the model (used in the output DataFrame).\n",
    "\n",
    "    carb_list : list of str\n",
    "        List of exchange reaction IDs corresponding to carbon sources to be tested.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results_df : pandas.DataFrame\n",
    "        DataFrame with columns ['Model', 'Carbon_Source', 'Objective_Value'].\n",
    "\n",
    "    flux_activity_df : pandas.DataFrame\n",
    "        Boolean DataFrame with reactions as rows and carbon sources as columns.\n",
    "        True indicates the reaction carried flux in that condition.\n",
    "\n",
    "    filtered_flux_activity_df : pandas.DataFrame\n",
    "        Subset of `flux_activity_df` containing only reactions that are active\n",
    "        in some but not all carbon source conditions.\n",
    "    \"\"\"\n",
    "    flux_threshold = 1e-6  # Minimum threshold to consider flux as active\n",
    "\n",
    "    results = []\n",
    "    flux_activity_df = pd.DataFrame({'Reaction': [rxn.id for rxn in model.reactions]})\n",
    "    flux_activity_df.set_index('Reaction', inplace=True)\n",
    "\n",
    "    for carb in carb_list:\n",
    "        model_temp = model.copy()\n",
    "\n",
    "        # Block all carbon sources except the current one\n",
    "        for rxn_id in carb_list:\n",
    "            if rxn_id in model_temp.reactions:\n",
    "                rxn = model_temp.reactions.get_by_id(rxn_id)\n",
    "                if rxn_id == carb:\n",
    "                    rxn.lower_bound = -10.0\n",
    "                    rxn.upper_bound = 1000.0\n",
    "                else:\n",
    "                    rxn.lower_bound = 0.0\n",
    "                    rxn.upper_bound = 0.0\n",
    "\n",
    "        # Run FBA\n",
    "        solution = model_temp.optimize()\n",
    "\n",
    "        # Record objective value\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Carbon_Source': carb,\n",
    "            'Objective_Value': solution.objective_value\n",
    "        })\n",
    "\n",
    "        # Record which reactions carry flux\n",
    "        active_flux = solution.fluxes.abs() > flux_threshold\n",
    "        flux_activity_df[carb] = active_flux\n",
    "\n",
    "    # Filter reactions active in some but not all conditions\n",
    "    filtered_flux_activity_df = flux_activity_df[\n",
    "        ~(flux_activity_df.all(axis=1) | ~flux_activity_df.any(axis=1))\n",
    "    ]\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df, flux_activity_df, filtered_flux_activity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the project root path by going up from the notebook location\n",
    "notebook_dir = Path(__file__).parent if '__file__' in globals() else Path().resolve()\n",
    "project_root = notebook_dir.parent.parent  # Go up from /code/GEM_Reduction/\n",
    "\n",
    "# Construct raw paths \n",
    "raw_data_path = project_root / \"data\" / \"raw\" \n",
    "raw_sbml_path = raw_data_path / \"sbml_files\" \n",
    "raw_mat_path = raw_data_path / \"matlab_files\" \n",
    "raw_csv_path = raw_data_path / \"csv_files\" \n",
    "\n",
    "# Construct processed paths \n",
    "processed_data_path = project_root / \"data\" / \"processed\" \n",
    "processed_sbml_path = processed_data_path / \"sbml_files\" \n",
    "processed_csv_path = processed_data_path / \"csv_files\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read model\n",
    "model = read_sbml_model(str(raw_sbml_path / \"iMS520.xml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pairs coupled and reactions blocked by F2C2\n",
    "Coupled_Pairs_df = pd.read_csv(raw_csv_path / 'fctable_iMS520.csv', header=None)\n",
    "F2C2_Blocked_Reactions_df = pd.read_csv(raw_csv_path / 'blocked_reactions_iMS520.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximize\n",
      "1.0*biomass_BIF - 1.0*biomass_BIF_reverse_508ec\n"
     ]
    }
   ],
   "source": [
    "print(model.objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_id = \"R_biomass_BIF\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exchange Reactions\n",
    "`fastcc` removes all reactions that **can never carry non-zero flux** in **steady state**, based on current bounds. This means:\n",
    "\n",
    "**For a general reduced model** (all potentially active reactions retained):\n",
    "- All **exchange reactions** should be temporarily opened to allow **both uptake and secretion** (e.g., `-10` to `1000`).\n",
    "- This ensures they aren't removed by `fastcc`.\n",
    "- Bounds can be **tightened again afterward**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create a deep copy of the model to avoid modifying the original\n",
    "model_copy = copy.deepcopy(model)\n",
    "\n",
    "# allow flux in and out for all exchange reactions\n",
    "for rxn in model_copy.exchanges:\n",
    "    rxn.lower_bound = -10\n",
    "    rxn.upper_bound = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export as .mat for matlab applications\n",
    "\n",
    "save_matlab_model(model_copy, raw_mat_path / \"iMS520.mat\") # use generic model to get unbiased couplings (filter later!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FASTCC model reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Luca/opt/anaconda3/envs/cobra_escher_env/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    }
   ],
   "source": [
    "# Reduce model with COBRApy FASTCC \n",
    "consistent_generic_model = fastcc(model_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F2C2 Coupling Integration\n",
    "* Coupled_Pairs_df: Interpretation for element (i, j):\n",
    "    *  0 - uncoupled\n",
    "    * 1 - fully coupled\n",
    "    * 2 - partially coupled\n",
    "    * 3 - reaction i is directionally coupled to j\n",
    "    * 4 - reaction j is directionally coupled to i\n",
    "* F2C2_Blocked_Reactions_df:\n",
    "    * 1 corresponding to a blocked reaction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Make F2C2 Data accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add reaction annotations to match F2C2 blocked reactions\n",
    "model_rxns = [rxn.id for rxn in model.reactions]\n",
    "F2C2_Blocked_Reactions_df.loc[len(F2C2_Blocked_Reactions_df)] = model_rxns\n",
    "\n",
    "# Identify unblocked reactions from the second row (index 1)\n",
    "unblocked_mask = F2C2_Blocked_Reactions_df.loc[0] == 0\n",
    "unblocked_reactions = F2C2_Blocked_Reactions_df.loc[1][unblocked_mask].tolist()\n",
    "\n",
    "# Update Coupled_Pairs_df index and columns with unblocked reactions\n",
    "Coupled_Pairs_df.index = unblocked_reactions\n",
    "Coupled_Pairs_df.columns = unblocked_reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of how many fully coupled pairs\n",
    "\n",
    "fully_coupled_count = ((Coupled_Pairs_df == 1).sum().sum()) - 631"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*SideQuest* : Investigate difference in 'blocking' between FASTCC and F2C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and convert reactions from models to sets for fast comparison\n",
    "generic_rxns = {rxn.id for rxn in consistent_generic_model.reactions}\n",
    "f2c2_unblocked_rxns = set(unblocked_reactions)\n",
    "\n",
    "# Compare overlaps and differences\n",
    "overlap_generic = list(generic_rxns & f2c2_unblocked_rxns)\n",
    "\n",
    "# Reactions unblocked by F2C2 but removed by FASTCC\n",
    "missing_from_generic = list(f2c2_unblocked_rxns - generic_rxns)\n",
    "\n",
    "# Reactions kept by FASTCC but blocked by F2C2 (ideally empty)\n",
    "unexpected_in_generic = list(generic_rxns - f2c2_unblocked_rxns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Implement Enzyme Subsets into model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a graph of fully coupled reactions\n",
    "G = nx.Graph()\n",
    "\n",
    "for row in Coupled_Pairs_df.index:\n",
    "    for col in Coupled_Pairs_df.columns:\n",
    "        if Coupled_Pairs_df.loc[row, col] == 1 and row != col:\n",
    "            G.add_edge(row, col)\n",
    "\n",
    "# Find connected components (fully coupled groups)\n",
    "coupled_groups = list(nx.connected_components(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from reaction ID to COBRA group name\n",
    "reaction_to_group = {}\n",
    "\n",
    "for group in model.groups:\n",
    "    group_name = group.name\n",
    "    for member in group.members:\n",
    "        if hasattr(member, 'id'):  # make sure it's a Reaction, not a Metabolite or Gene\n",
    "            reaction_to_group[member.id] = group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine coupled groups with their annotated groups in the COBRA model and obtain in- and output of coupled groups\n",
    "\n",
    "combined_data = []\n",
    "\n",
    "for group in coupled_groups:\n",
    "    group_reactions = list(group)\n",
    "    \n",
    "    # COBRA Group Names\n",
    "    group_names = set()\n",
    "    for rxn in group_reactions:\n",
    "        if rxn in reaction_to_group:\n",
    "            group_names.add(reaction_to_group[rxn])\n",
    "    \n",
    "    # Net Stoichiometry\n",
    "    stoich = defaultdict(float)\n",
    "    for rxn_id in group_reactions:\n",
    "        rxn = model.reactions.get_by_id(rxn_id)\n",
    "        for met, coeff in rxn.metabolites.items():\n",
    "            stoich[met] += coeff\n",
    "\n",
    "    inputs = [met.id for met, coeff in stoich.items() if coeff < 0]\n",
    "    outputs = [met.id for met, coeff in stoich.items() if coeff > 0]\n",
    "\n",
    "    # Append Combined Info\n",
    "    combined_data.append({\n",
    "        \"Coupled_Reactions\": group_reactions,\n",
    "        \"COBRA_Groups\": list(group_names) if group_names else [\"Unassigned\"],\n",
    "        \"Num_Inputs\": len(inputs),\n",
    "        \"Num_Outputs\": len(outputs),\n",
    "        \"Input_Metabolites\": inputs,\n",
    "        \"Output_Metabolites\": outputs\n",
    "    })\n",
    "\n",
    "# Create the final DataFrame\n",
    "Fully_Coupled_df = pd.DataFrame(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the reactions per group form a single connected component (i.e., fully connected cluster)\n",
    "Fully_Coupled_df['Cluster'] = Fully_Coupled_df['Coupled_Reactions'].apply(\n",
    "    lambda rxn_list: are_reactions_interconnected(consistent_generic_model, rxn_list)\n",
    ")\n",
    "\n",
    "# Remove Entries that are not fully connected\n",
    "\n",
    "Fully_Coupled_df = Fully_Coupled_df[Fully_Coupled_df['Cluster'] != False]\n",
    "\n",
    "# Remove objective function (if in df)\n",
    "Fully_Coupled_df['Reactions'] = Fully_Coupled_df['Coupled_Reactions'].apply(lambda rxns: [r for r in rxns if r != objective_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Option 1*: \"Full\" Lumping including exchange reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform \"full\" lumping (incl. all reactions)\n",
    "\n",
    "lumped_model, lumping_log = lump_reaction(consistent_generic_model, Fully_Coupled_df, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Option 2*: Selective lumping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERSION 1: Remove rows where 'Exchange' (or 'Exchange ') appears in COBRA_Groups \n",
    "\n",
    "Fully_Coupled_df_v1 = Fully_Coupled_df[~Fully_Coupled_df['COBRA_Groups'].apply(lambda groups: any(g.strip() == 'Exchange' for g in groups))].copy()\n",
    "\n",
    "\n",
    "# VERSION 2: Remove EX_ reactions from Coupled_Reactions and remove 'Exchange' (or 'Exchange ') from COBRA_Groups \n",
    "\n",
    "new_reactions = []\n",
    "new_groups = []\n",
    "\n",
    "for idx, row in Fully_Coupled_df.iterrows():\n",
    "    # Remove reactions that start with 'EX_'\n",
    "    filtered_rxns = [rxn for rxn in row['Coupled_Reactions'] if not rxn.startswith('EX_')]\n",
    "\n",
    "    # Remove 'Exchange' or 'Exchange ' (trailing spaces)\n",
    "    filtered_groups = [grp for grp in row['COBRA_Groups'] if grp.strip() != 'Exchange']\n",
    "\n",
    "    # Keep only if at least 2 reactions remain\n",
    "    if len(filtered_rxns) >= 2:\n",
    "        new_reactions.append(filtered_rxns)\n",
    "        new_groups.append(filtered_groups)\n",
    "\n",
    "# Rebuild the filtered DataFrame\n",
    "Fully_Coupled_df_v2 = pd.DataFrame({\n",
    "    'Coupled_Reactions': new_reactions,\n",
    "    'COBRA_Groups': new_groups\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform lumping only for groups that are not at all connected to exchange reaction\n",
    "\n",
    "lumped_model_v1, lumping_log_v1 = lump_reaction(consistent_generic_model, Fully_Coupled_df_v1, verbose=False, label_type=\"Group\", Search_COBRA_groups=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform lumping only excl. exchange reactions \n",
    "\n",
    "lumped_model_v2, lumping_log_v2 = lump_reaction(consistent_generic_model, coupled_df=Fully_Coupled_df_v2, verbose=False, label_type=\"Group\", Search_COBRA_groups=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_length = Fully_Coupled_df_v2['Coupled_Reactions'].apply(len).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All pseudo-reactions validated — they can carry flux.\n"
     ]
    }
   ],
   "source": [
    "# Get all pseudo-reaction IDs\n",
    "pseudo_reactions = [rxn.id for rxn in lumped_model_v2.reactions if rxn.id.startswith(\"Pseudo_\")]\n",
    "\n",
    "# Use Flux Variability Analysis to test max possible flux\n",
    "# fraction_of_optimum=0.0 tells FVA to ignore the model's objective and simply check whether each reaction can carry any flux under the current constraints.\n",
    "fva_results = flux_variability_analysis(lumped_model_v2, reaction_list=pseudo_reactions, fraction_of_optimum=0.0) \n",
    "\n",
    "# Identify if any pseudoreactions are blocked (min=max=0)\n",
    "fva_results['is_blocked'] = (fva_results['minimum'].abs() < 1e-6) & (fva_results['maximum'].abs() < 1e-6)\n",
    "\n",
    "# Check if any reactions are blocked\n",
    "if not fva_results['is_blocked'].any():\n",
    "    print(\"✅ All pseudo-reactions validated — they can carry flux.\")\n",
    "else:\n",
    "    print(\"❌ Some pseudo-reactions are blocked and cannot carry flux:\")\n",
    "    blocked = fva_results[fva_results['is_blocked']]\n",
    "    print(blocked[['minimum', 'maximum']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module-oriented Reaction Lumping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Group Sanity Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping for all groups and their corresponding reactions\n",
    "\n",
    "# Extract groups and their reactions\n",
    "group_mapping_data = [\n",
    "    {\n",
    "        'COBRA_Group': group.name,\n",
    "        'Reactions': [member.id for member in group.members if member.__class__.__name__ == 'Reaction']\n",
    "    }\n",
    "    for group in lumped_model_v2.groups\n",
    "    if any(member.__class__.__name__ == 'Reaction' for member in group.members)\n",
    "]\n",
    "Raw_Group_df = pd.DataFrame(group_mapping_data)\n",
    "\n",
    "# Normalize group names (case + spacing)\n",
    "Raw_Group_df['Normalized_Group'] = Raw_Group_df['COBRA_Group'].apply(\n",
    "    lambda x: ' '.join(x.strip().split()).title()\n",
    ")\n",
    "\n",
    "# Group by normalized name, merge reactions, remove duplicates\n",
    "Normalized_Group_df = (\n",
    "    Raw_Group_df.groupby('Normalized_Group')\n",
    "    .agg({'Reactions': lambda lists: list(set(r for sub in lists for r in sub))})\n",
    "    .reset_index()\n",
    "    .rename(columns={'Normalized_Group': 'COBRA_Group'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect suspiciously similar group names using fuzzy matching\n",
    "\n",
    "group_names = Normalized_Group_df['COBRA_Group'].tolist()\n",
    "suspicious_matches = []\n",
    "SIMILARITY_THRESHOLD = 85 # max.: 100 \n",
    "\n",
    "for i, name1 in enumerate(group_names):\n",
    "    for j, name2 in enumerate(group_names):\n",
    "        if i >= j:\n",
    "            continue\n",
    "        score = fuzz.ratio(name1, name2)\n",
    "        if score >= SIMILARITY_THRESHOLD and name1 != name2:\n",
    "            suspicious_matches.append({\n",
    "                'Group_1': name1,\n",
    "                'Group_2': name2,\n",
    "                'Similarity_Score': score\n",
    "            })\n",
    "\n",
    "# Build suspicious match DataFrame and default merge plan\n",
    "suspicious_df = pd.DataFrame(suspicious_matches)\n",
    "suspicious_df['Merge_Into'] = suspicious_df['Group_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Check of suspicious match DataFrame + check of merge names\n",
    "\n",
    "suspicious_df.loc[suspicious_df['Group_1'] == 'Pentose Phosphate Pathwa', 'Merge_Into'] = 'Pentose Phosphate Pathway'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping from each group name to its cleaned (merged) name\n",
    "merge_map = {}\n",
    "\n",
    "for _, row in suspicious_df.iterrows():\n",
    "    merge_map[row['Group_1']] = row['Merge_Into']\n",
    "    merge_map[row['Group_2']] = row['Merge_Into']\n",
    "\n",
    "# Apply merge mapping to normalized group names\n",
    "Normalized_Group_df['Final_Group'] = Normalized_Group_df['COBRA_Group'].apply(\n",
    "    lambda g: merge_map.get(g, g)\n",
    ")\n",
    "\n",
    "# Re-merge by Final_Group, removing duplicates in reaction lists\n",
    "Final_Group_df = (\n",
    "    Normalized_Group_df.groupby('Final_Group')\n",
    "    .agg({'Reactions': lambda lists: list(set(r for sub in lists for r in sub))})\n",
    "    .reset_index()\n",
    "    .rename(columns={'Final_Group': 'COBRA_Group'})\n",
    ")\n",
    "\n",
    "# Add a column for the number of reactions per group\n",
    "Final_Group_df['Reaction_Count'] = Final_Group_df['Reactions'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the reactions per group form a single connected component (i.e., fully connected cluster)\n",
    "Final_Group_df['Cluster'] = Final_Group_df['Reactions'].apply(\n",
    "    lambda rxn_list: are_reactions_interconnected(lumped_model_v2, rxn_list)\n",
    ")\n",
    "\n",
    "# Remove Entries that are not fully connected\n",
    "\n",
    "Final_Group_df = Final_Group_df[Final_Group_df['Cluster'] != False]\n",
    "\n",
    "# Remove objective function (if in df)\n",
    "Final_Group_df['Reactions'] = Final_Group_df['Reactions'].apply(lambda rxns: [r for r in rxns if r != objective_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Decide which groups to merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export for manual investigation\n",
    "\n",
    "Final_Group_df.to_csv(raw_csv_path / 'iMS520_lumpmodule.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define modules that should be left intact (no lumping)\n",
    "\n",
    "avoid_list = ['Anaplerotic Reactions','Citrate Acid Cycle','Exchange','Fructose And Mannose Metabolism','Galacto-N-Biose Pathway','Galactose Metabolism','Glycolysis','Glycolysis/Gluconeogenesis',\n",
    "              'Lacto-N-Biose','Pentose And Glucoronate Interconversions','Pentose And Glucoronate Metabolism','Pentose Phosphate Pathway','Phosphoketolase Pathway','Pyruvate Metabolism',\n",
    "              'Starch Sucrose Metabolis','Starch Sucrose Metabolismgalactose Metabolism','Transport','Unassigned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter & deduplicate rows in the avoid_list\n",
    "avoid_reactions_series = Final_Group_df[Final_Group_df['COBRA_Group'].isin(avoid_list)]['Reactions']\n",
    "\n",
    "avoid_reactions = set()\n",
    "for reaction_list in avoid_reactions_series:\n",
    "    avoid_reactions.update(reaction_list)\n",
    "\n",
    "# Make a deep copy of the DataFrame to avoid changing the original\n",
    "Lump_df = Final_Group_df.copy(deep=True)\n",
    "\n",
    "# Iterate over rows not in avoid_list and clean their Reactions\n",
    "for idx, row in Lump_df.iterrows():\n",
    "    if row['COBRA_Group'] not in avoid_list:\n",
    "        original_reactions = set(row['Reactions'])\n",
    "        updated_reactions = original_reactions - avoid_reactions\n",
    "\n",
    "        if original_reactions != updated_reactions:\n",
    "            removed = original_reactions & avoid_reactions\n",
    "            # print(f\"Cleaning group '{row['COBRA_Group']}': removed {len(removed)} reaction(s): {removed}\")\n",
    "\n",
    "        Lump_df.at[idx, 'Reactions'] = list(updated_reactions)\n",
    "\n",
    "# Identify rows where 'Reactions' is an empty list\n",
    "empty_rows = Lump_df[Lump_df['Reactions'].apply(lambda x: len(x) == 0)]\n",
    "\n",
    "# Remove these rows from the cleaned DataFrame\n",
    "Final_Lump_df = Lump_df[Lump_df['Reactions'].apply(lambda x: len(x) > 1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the reactions per group form a single connected component (i.e., fully connected cluster)\n",
    "Final_Lump_df['Cluster_New'] = Final_Lump_df['Reactions'].apply(\n",
    "    lambda rxn_list: are_reactions_interconnected(lumped_model_v2, rxn_list))\n",
    "\n",
    "# Remove Entries that are not fully connected\n",
    "\n",
    "Final_Lump_df = Final_Lump_df[Final_Lump_df['Cluster'] != False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Lump modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where 'COBRA_Group' is in the avoid_list\n",
    "Filtered_Lump_df = Final_Lump_df[~Final_Lump_df['COBRA_Group'].isin(avoid_list)].copy() # these won't get lumped!\n",
    "\n",
    "#  Deduplicate reactions across all rows (ensures each reaction appears only once)\n",
    "seen_reactions = set()\n",
    "for idx, row in Filtered_Lump_df.iterrows():\n",
    "    unique_reactions = [rxn for rxn in row['Reactions'] if rxn not in seen_reactions]\n",
    "    seen_reactions.update(unique_reactions)\n",
    "    Filtered_Lump_df.at[idx, 'Reactions'] = unique_reactions\n",
    "\n",
    "# Remove reactions that start with \"EX_\"\n",
    "for idx, row in Filtered_Lump_df.iterrows():\n",
    "    non_exchange_reactions = [rxn for rxn in row['Reactions'] if not rxn.startswith(\"EX_\")]\n",
    "    Filtered_Lump_df.at[idx, 'Reactions'] = non_exchange_reactions\n",
    "\n",
    "# Remove rows with empty reaction lists\n",
    "Filtered_Lump_df = Filtered_Lump_df[Filtered_Lump_df['Reactions'].apply(len) > 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform lumping only excl. exchange reactions \n",
    "\n",
    "lumped_model_final, lump_log_final = lump_reaction(lumped_model_v2, coupled_df=Filtered_Lump_df, verbose=False, Search_COBRA_groups=True, label_type=\"Module\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4**: Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All pseudo-reactions validated — they can carry flux.\n"
     ]
    }
   ],
   "source": [
    "# Get all pseudo-reaction IDs\n",
    "pseudo_reactions = [rxn.id for rxn in lumped_model_final.reactions if rxn.id.startswith(\"Pseudo_\")]\n",
    "\n",
    "# Use Flux Variability Analysis to test max possible flux\n",
    "# fraction_of_optimum=0.0 tells FVA to ignore the model's objective and simply check whether each reaction can carry any flux under the current constraints.\n",
    "fva_results = flux_variability_analysis(lumped_model_final, reaction_list=pseudo_reactions, fraction_of_optimum=0.0) \n",
    "\n",
    "# Identify if any pseudoreactions are blocked (min=max=0)\n",
    "fva_results['is_blocked'] = (fva_results['minimum'].abs() < 1e-6) & (fva_results['maximum'].abs() < 1e-6)\n",
    "\n",
    "# Check if any reactions are blocked\n",
    "if not fva_results['is_blocked'].any():\n",
    "    print(\"✅ All pseudo-reactions validated — they can carry flux.\")\n",
    "else:\n",
    "    print(\"❌ Some pseudo-reactions are blocked and cannot carry flux:\")\n",
    "    blocked = fva_results[fva_results['is_blocked']]\n",
    "    print(blocked[['minimum', 'maximum']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_sbml_model(lumped_model_final, processed_sbml_path / 'iMS520_red1.sbml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Went from original model (771 reactions) to a reduced generic model (249 reactions) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: Make condition-specific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Block reactions that are exchanged for compounds not in the medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define blocked reactions\n",
    "\n",
    "\n",
    "blocked_carbsource_reactions = ['D-xylose exchange', 'mannose exchange', 'D-ribose exchange', 'L-arabinose exchange', 'sucrose exchange','L-rhamnose exchange','cellobiose exchange',\n",
    "                                'lactose exchange','mellibiose exchange','raffinose exchange','maltotriose exchange','maltohexaose exchange','lnb exchange','gnb exchange']\n",
    "\n",
    "blocked_AA_reactions = ['histidine exchange', 'arginine exchange','tyrosine exchange ','lysine exchange','glycine exchange','alanine exchange','serine exchange', 'glutamate exchange', \n",
    "                        'glutamine exchange', 'aspartate exchange','asparagine exchange']\n",
    "\n",
    "blocked_noncategorical_reactions = ['methanethiol exchange','Cys-Gly Exchange','Methionine sulfoxide exchange','Shikimate exchange','putrescine exchange','spmd exchange','uracil exchange',\n",
    "                                    'xanthine exchange','hypoxanthine exchange']\n",
    "\n",
    "reactions_to_block = blocked_carbsource_reactions + blocked_AA_reactions + blocked_noncategorical_reactions\n",
    "\n",
    "# define carbon source reactions \n",
    "\n",
    "carbon_sources = ['glucose exchange','galactose exchange','fructose exchange','maltose exchange']\n",
    "\n",
    "# other medium components \n",
    "\n",
    "other_medium_components = [] # need to check Harolds File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy to not modify the generic model\n",
    "\n",
    "model_copy2 = copy.deepcopy(lumped_model_final)\n",
    "\n",
    "# block reactions and open carbon reactions (already open)\n",
    "\n",
    "for rxn in model_copy2.reactions:\n",
    "        if rxn.name in reactions_to_block:\n",
    "            rxn.lower_bound = 0.0\n",
    "            rxn.upper_bound = 0.0\n",
    "\n",
    "for rxn in model_copy2.reactions:\n",
    "        if rxn.name in carbon_sources:\n",
    "            rxn.lower_bound = -10\n",
    "            rxn.upper_bound = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: FASTCC on conditioned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Luca/opt/anaconda3/envs/cobra_escher_env/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    }
   ],
   "source": [
    "# produce conditioned model\n",
    "\n",
    "conditioned_model = fastcc(model_copy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_sbml_model(lumped_model_final, processed_sbml_path / 'iMS520_red2.sbml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Modify Directionalities of Exchanges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all exchange reactions\n",
    "\n",
    "exchange_reactions = [rxn for rxn in conditioned_model.reactions if rxn.id.startswith(\"EX_\")]\n",
    "exchange_names = [rxn.name for rxn in exchange_reactions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define whether these serve as nutrients or are secreted by the organism\n",
    "\n",
    "import_only = ['D-glucose exchange','fructose exchange','galactose exchange','maltose exchange','NH4 exchange','phosphate exchange','potassium exchange',\n",
    "               'molybdate exchange','cobalt+2 exchange','L-methionine exchange','Mg+2 exchange','Fe+2 exchange','Fe+3 exchange','Zn+2 exchange','calcium exchange',\n",
    "               'Cu+2 exchange','Mn+2 exchange', 'cysteine exchange','leucine exchange','isoleucine exchange','valine exchange','threonine exchange', 'tryptophan exchange',\n",
    "               'phenylalanine exchange','tyrosine exchange','proline exchange','thiamine exchange','biotin exchange','4-aminobenzoate exchange','pantethine exchange',\n",
    "               'riboflavine exchange','nicotinamide exchange','nicotinic acid exchange','folate exchange','cob(I)alamine exchange','menaquinone-4 exchange',]\n",
    "\n",
    "both = ['H2O exchange','proton exchange','chloride exchange']\n",
    "\n",
    "secretion_only = ['Formate exchange','lactate exchange','succinate exchange','acetate exchange','ethanol exchange','acetaldehyde exchange','H2S exchange',\n",
    "                  'carbon dioxide exchange', 'Hydrogen peroxide exchange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy model\n",
    "\n",
    "model_copy3 = copy.deepcopy(conditioned_model)\n",
    "\n",
    "# modifiy reaction bounds to mark nutrients / secretion products\n",
    "\n",
    "for rxn in model_copy3.reactions:\n",
    "        if rxn.name in import_only:\n",
    "            rxn.lower_bound = -10\n",
    "            rxn.upper_bound = 0.0\n",
    "\n",
    "for rxn in model_copy3.reactions:\n",
    "        if rxn.name in secretion_only:\n",
    "            rxn.lower_bound = 0\n",
    "            rxn.upper_bound = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify reversibilities\n",
    "\n",
    "for rxn in model_copy3.reactions:\n",
    "    if rxn.lower_bound < 0 and rxn.upper_bound == 0:\n",
    "        # Flip direction\n",
    "        original_stoich = rxn.metabolites\n",
    "        flipped_stoich = {met: -coeff for met, coeff in original_stoich.items()}\n",
    "\n",
    "        # Clear old stoichiometry and set new one\n",
    "        rxn.subtract_metabolites(original_stoich)\n",
    "        rxn.add_metabolites(flipped_stoich)\n",
    "\n",
    "        # Update bounds\n",
    "        old_lb = rxn.lower_bound\n",
    "        rxn.lower_bound = 0\n",
    "        rxn.upper_bound = abs(old_lb)\n",
    "\n",
    "        # Rename or tag\n",
    "        rxn.id = f\"{rxn.id}_flipped\"\n",
    "        rxn.name = f\"{rxn.name} (flipped)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_sbml_model(lumped_model_final, processed_sbml_path / 'iMS520_red3.sbml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: \n",
    "- The conditioned reduced model with modified reversibilities has 192 reactions\n",
    "- The generic reduced model has 249 reactions with 128 reversible reactions\n",
    "- The original model has 771 reactions with 206 reversible reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stoichiometric Matrix Rank: 166\n",
      "Number of Reactions: 190\n",
      "Degrees of Freedom: 24\n"
     ]
    }
   ],
   "source": [
    "# Get the stoichiometric matrix as a NumPy array\n",
    "stoich_dense = create_stoichiometric_matrix(model_copy3)  # Already a NumPy array\n",
    "\n",
    "# Compute the rank of the stoichiometric matrix\n",
    "rank = np.linalg.matrix_rank(stoich_dense)\n",
    "\n",
    "# Degrees of freedom\n",
    "num_reactions = len(model_copy3.reactions)\n",
    "dof = num_reactions - rank\n",
    "\n",
    "# Output\n",
    "print(f\"Stoichiometric Matrix Rank: {rank}\")\n",
    "print(f\"Number of Reactions: {num_reactions}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "carb_list = ['EX_glc-D(e)_flipped','EX_fru(e)_flipped','EX_gal(e)_flipped','EX_malt(e)_flipped']\n",
    "carb_list_original = ['EX_glc-D(e)','EX_fru(e)','EX_gal(e)','EX_malt(e)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run analysis for both models\n",
    "results_final, flux_activity_final, filtered_flux_final = analyze_model(lumped_model_final, 'Final_Model',carb_list_original)\n",
    "results_original, flux_activity_original, filtered_flux_original = analyze_model(consistent_generic_model, 'Consistent',carb_list_original)\n",
    "results_context, flux_activity_context, filtered_flux_context = analyze_model(model_copy3, 'Context',carb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "Objective_comparison_df = pd.concat([results_final, results_original,results_context], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Objective_comparison_df.to_csv(raw_csv_path / 'iMS520_FBA_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cobra_escher_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
