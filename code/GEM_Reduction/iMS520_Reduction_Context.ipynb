{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Standard Library and 3rd Party Imports \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cobra\n",
    "import networkx as nx\n",
    "import scipy\n",
    "import copy\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import chain, combinations\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COBRA imports\n",
    "\n",
    "from cobra import Model, Reaction\n",
    "from cobra.core import Group\n",
    "from cobra.flux_analysis import flux_variability_analysis\n",
    "from cobra.flux_analysis.fastcc import fastcc\n",
    "from cobra.io import read_sbml_model, save_matlab_model, write_sbml_model\n",
    "from cobra.util.solver import linear_reaction_coefficients\n",
    "from cobra.util.array import create_stoichiometric_matrix\n",
    "from rapidfuzz import fuzz, process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lump_reaction(model, coupled_df, verbose=True, Search_COBRA_groups=False, label_type=\"Group\"):\n",
    "    \"\"\"\n",
    "    Create a lumped model by replacing fully coupled reaction groups with pseudo-reactions.\n",
    "\n",
    "    Parameters:\n",
    "    - model: cobra.Model (the original model, will remain unchanged)\n",
    "    - coupled_df: pd.DataFrame with either:\n",
    "        - columns ['Coupled_Reactions', 'COBRA_Groups'] (default format), or\n",
    "        - column ['Reactions'], and Search_COBRA_groups=True\n",
    "    - verbose: bool, if True print progress messages\n",
    "    - Search_COBRA_groups: bool, if True, search model groups for each reaction if not supplied\n",
    "    - label_type: str, either 'Group' or 'Module' — used in pseudo-reaction naming (required)\n",
    "\n",
    "    Returns:\n",
    "    - model_lumped: cobra.Model with pseudo-reactions added\n",
    "    - translation_df: pd.DataFrame mapping pseudo-reactions to original reactions and groups\n",
    "    \"\"\"\n",
    "    import copy\n",
    "    from cobra import Reaction\n",
    "    from collections import defaultdict\n",
    "    import pandas as pd\n",
    "\n",
    "    model_lumped = copy.deepcopy(model)\n",
    "    translation_data = []\n",
    "\n",
    "    # Handle case with only 'Reactions' column — determine COBRA_Groups if needed\n",
    "    if Search_COBRA_groups and 'Reactions' in coupled_df.columns:\n",
    "        cobra_groups_list = []\n",
    "        for i, row in coupled_df.iterrows():\n",
    "            reaction_list = row['Reactions']\n",
    "            found_groups = set()\n",
    "            for rxn_id in reaction_list:\n",
    "                for group in model.groups:\n",
    "                    if rxn_id in [rxn.id for rxn in group.members]:\n",
    "                        found_groups.add(group.name)\n",
    "            cobra_groups_list.append(list(found_groups))\n",
    "        coupled_df = coupled_df.rename(columns={'Reactions': 'Coupled_Reactions'})\n",
    "        coupled_df['COBRA_Groups'] = cobra_groups_list\n",
    "\n",
    "    for i, row in coupled_df.iterrows():\n",
    "        group_reactions = row['Coupled_Reactions']\n",
    "        cobra_groups = row['COBRA_Groups']\n",
    "\n",
    "        valid_reactions = []\n",
    "        for rxn_id in group_reactions:\n",
    "            if rxn_id in model_lumped.reactions:\n",
    "                valid_reactions.append(rxn_id)\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"⚠️ Reaction '{rxn_id}' not found in model — skipping.\")\n",
    "\n",
    "        if len(valid_reactions) < 2:\n",
    "            if verbose:\n",
    "                print(f\"⏭️ Skipping group {i} — fewer than 2 valid reactions.\")\n",
    "            continue\n",
    "\n",
    "        lower_bounds = []\n",
    "        upper_bounds = []\n",
    "        for rxn_id in valid_reactions:\n",
    "            rxn = model_lumped.reactions.get_by_id(rxn_id)\n",
    "            lower_bounds.append(rxn.lower_bound)\n",
    "            upper_bounds.append(rxn.upper_bound)\n",
    "        min_lb = max(lower_bounds)\n",
    "        max_ub = min(upper_bounds)\n",
    "\n",
    "        net_stoich = defaultdict(float)\n",
    "        for rxn_id in valid_reactions:\n",
    "            rxn = model_lumped.reactions.get_by_id(rxn_id)\n",
    "            for met, coeff in rxn.metabolites.items():\n",
    "                net_stoich[met] += coeff\n",
    "\n",
    "        cleaned_stoich = {met: coeff for met, coeff in net_stoich.items() if abs(coeff) > 1e-10}\n",
    "\n",
    "        pseudo_id = f\"Pseudo_{label_type}_{i}\"\n",
    "        pseudo_rxn = Reaction(id=pseudo_id)\n",
    "        pseudo_rxn.name = f\"Lumped reaction for: {', '.join(valid_reactions)}\"\n",
    "        pseudo_rxn.lower_bound = min_lb\n",
    "        pseudo_rxn.upper_bound = max_ub\n",
    "        pseudo_rxn.add_metabolites(cleaned_stoich)\n",
    "\n",
    "        model_lumped.add_reactions([pseudo_rxn])\n",
    "\n",
    "        for group in model_lumped.groups:\n",
    "            if group.name in cobra_groups:\n",
    "                group.add_members([pseudo_rxn])\n",
    "\n",
    "        for rxn_id in valid_reactions:\n",
    "            rxn = model_lumped.reactions.get_by_id(rxn_id)\n",
    "            for group in model_lumped.groups:\n",
    "                if rxn in group.members:\n",
    "                    group.members.remove(rxn)\n",
    "            model_lumped.reactions.remove(rxn)\n",
    "\n",
    "        translation_data.append({\n",
    "            'Pseudo_Reaction_ID': pseudo_id,\n",
    "            'Original_Reactions': valid_reactions,\n",
    "            'COBRA_Groups': cobra_groups\n",
    "        })\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"✅ {label_type} {i}: Created '{pseudo_id}' from {valid_reactions}\")\n",
    "\n",
    "    translation_df = pd.DataFrame(translation_data)\n",
    "    return model_lumped, translation_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_reactions_interconnected(model, reaction_ids):\n",
    "    \"\"\"\n",
    "    Check whether a list of reactions are all interconnected via shared metabolites.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: cobra.Model\n",
    "    - reaction_ids: list of reaction IDs to test\n",
    "\n",
    "    Returns:\n",
    "    - bool: True if all reactions are connected via shared metabolites\n",
    "    \"\"\"\n",
    "    # Create a graph where nodes = reactions, edges = shared metabolite\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(reaction_ids)\n",
    "\n",
    "    # Build edges based on shared metabolites\n",
    "    for i, rxn1_id in enumerate(reaction_ids):\n",
    "        if rxn1_id not in model.reactions:\n",
    "            continue\n",
    "        rxn1 = model.reactions.get_by_id(rxn1_id)\n",
    "        mets1 = set(rxn1.metabolites)\n",
    "\n",
    "        for rxn2_id in reaction_ids[i+1:]:\n",
    "            if rxn2_id not in model.reactions:\n",
    "                continue\n",
    "            rxn2 = model.reactions.get_by_id(rxn2_id)\n",
    "            mets2 = set(rxn2.metabolites)\n",
    "\n",
    "            # Add edge if they share at least one metabolite\n",
    "            if mets1 & mets2:\n",
    "                G.add_edge(rxn1_id, rxn2_id)\n",
    "\n",
    "    # Check if the graph is fully connected\n",
    "    return nx.is_connected(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_model(model, model_name, carb_list, Direction=\"Original\"):\n",
    "    \"\"\"\n",
    "    Run FBA simulations for a COBRA model across multiple carbon source conditions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : cobra.Model\n",
    "        The COBRA model to simulate.\n",
    "\n",
    "    model_name : str\n",
    "        Identifier for the model (used in the output DataFrame).\n",
    "\n",
    "    carb_list : list of str\n",
    "        List of exchange reaction IDs corresponding to carbon sources to be tested.\n",
    "\n",
    "    Direction : str, optional\n",
    "        Flux direction for the carbon sources:\n",
    "        - \"Original\" (default): lb = -10, ub = 10 (uptake allowed)\n",
    "        - \"Reversed\": lb = 0, ub = 10 (uptake blocked, export only)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results_df : pandas.DataFrame\n",
    "        DataFrame with columns ['Model', 'Carbon_Source', 'Objective_Value'].\n",
    "\n",
    "    flux_activity_df : pandas.DataFrame\n",
    "        Boolean DataFrame with reactions as rows and carbon sources as columns.\n",
    "\n",
    "    filtered_flux_activity_df : pandas.DataFrame\n",
    "        Subset of `flux_activity_df` with reactions active in some but not all conditions.\n",
    "    \"\"\"\n",
    "    flux_threshold = 1e-6  # Minimum flux considered active\n",
    "    results = []\n",
    "\n",
    "    # Initialize flux activity matrix\n",
    "    flux_activity_df = pd.DataFrame({'Reaction': [rxn.id for rxn in model.reactions]})\n",
    "    flux_activity_df.set_index('Reaction', inplace=True)\n",
    "\n",
    "    for carb in carb_list:\n",
    "        model_temp = model.copy()\n",
    "\n",
    "        for rxn_id in carb_list:\n",
    "            if rxn_id in model_temp.reactions:\n",
    "                rxn = model_temp.reactions.get_by_id(rxn_id)\n",
    "\n",
    "                if rxn_id == carb:\n",
    "                    if Direction == \"Reversed\":\n",
    "                        rxn.lower_bound = 0.0\n",
    "                        rxn.upper_bound = 10.0\n",
    "                    else:  # \"Original\"\n",
    "                        rxn.lower_bound = -10.0\n",
    "                        rxn.upper_bound = 0\n",
    "                else:\n",
    "                    rxn.lower_bound = 0.0\n",
    "                    rxn.upper_bound = 0.0\n",
    "\n",
    "        # Run FBA\n",
    "        solution = model_temp.optimize()\n",
    "\n",
    "        # Record results\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Carbon_Source': carb,\n",
    "            'Objective_Value': solution.objective_value\n",
    "        })\n",
    "\n",
    "        # Track active reactions\n",
    "        active_flux = solution.fluxes.abs() > flux_threshold\n",
    "        flux_activity_df[carb] = active_flux\n",
    "\n",
    "    # Keep reactions active in some but not all conditions\n",
    "    filtered_flux_activity_df = flux_activity_df[\n",
    "        ~(flux_activity_df.all(axis=1) | ~flux_activity_df.any(axis=1))\n",
    "    ]\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df, flux_activity_df, filtered_flux_activity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the project root path by going up from the notebook location\n",
    "notebook_dir = Path(__file__).parent if '__file__' in globals() else Path().resolve()\n",
    "project_root = notebook_dir.parent.parent  \n",
    "\n",
    "# Construct raw paths \n",
    "raw_data_path = project_root / \"data\" / \"raw\" \n",
    "raw_sbml_path = raw_data_path / \"sbml_files\" \n",
    "raw_mat_path = raw_data_path / \"matlab_files\" \n",
    "raw_csv_path = raw_data_path / \"csv_files\" \n",
    "\n",
    "# Construct processed paths \n",
    "processed_data_path = project_root / \"data\" / \"processed\" \n",
    "processed_sbml_path = processed_data_path / \"sbml_files\" \n",
    "processed_csv_path = processed_data_path / \"csv_files\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read model\n",
    "model = read_sbml_model(str(raw_sbml_path / \"iMS520.xml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pairs coupled and reactions blocked by F2C2\n",
    "Coupled_Pairs_df = pd.read_csv(raw_csv_path / 'fctable_iMS520_context.csv', header=None)\n",
    "F2C2_Blocked_Reactions_df = pd.read_csv(raw_csv_path / 'blocked_reactions_iMS520_context.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a curated list of exchange reactions from file\n",
    "exchange_df_full = pd.read_csv(raw_csv_path / 'iMS520_exchanges.csv')\n",
    "\n",
    "# Context-specific exchanges\n",
    "final_exchanges_df = pd.read_csv(raw_csv_path / 'iMS520_context_exchanges.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract Information** from original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_id = \"biomass_BIF\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Basics\n",
    "- Model ID: COBRAModel\n",
    "- Number of Reactions: 771\n",
    "- Number of Metabolites: 680\n",
    "- Number of Genes: 520\n",
    "- Number of Exchange Reactions: 88\n",
    "- Reversible Reactions: 205\n",
    "- Irreversible Reactions: 566\n",
    "- Objective reaction(s): biomass_BIF\n",
    "\n",
    "- FBA Objective value (biomass): 0.3144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stoichiometric Matrix Rank: 620\n",
      "Number of Reactions: 771\n",
      "Degrees of Freedom: 151\n"
     ]
    }
   ],
   "source": [
    "# Get the stoichiometric matrix as a NumPy array\n",
    "stoich_dense = create_stoichiometric_matrix(model)  # Already a NumPy array\n",
    "\n",
    "# Compute the rank of the stoichiometric matrix\n",
    "rank = np.linalg.matrix_rank(stoich_dense)\n",
    "\n",
    "# Degrees of freedom\n",
    "num_reactions = len(model.reactions)\n",
    "dof = num_reactions - rank\n",
    "\n",
    "# Output\n",
    "print(f\"Stoichiometric Matrix Rank: {rank}\")\n",
    "print(f\"Number of Reactions: {num_reactions}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Exchanges (Context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a deep copy of the model to avoid modifying the original\n",
    "model_copy = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Create Files to invest exchanges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run FBA on the model\n",
    "solution = model_copy.optimize()\n",
    "\n",
    "# Extract all exchange reactions from the model\n",
    "exchange_reactions = model_copy.exchanges\n",
    "\n",
    "# Create a DataFrame summarizing each exchange reaction\n",
    "exchange_df = pd.DataFrame([{\n",
    "    \"ID\": rxn.id,\n",
    "    \"Name\": rxn.name,\n",
    "    \"Lower_FB\": rxn.lower_bound,\n",
    "    \"Upper_FB\": rxn.upper_bound,\n",
    "    \"Flux\": solution.fluxes.get(rxn.id, 0.0),\n",
    "    \"Active_in_FBA\": abs(solution.fluxes.get(rxn.id, 0.0)) > 1e-10,\n",
    "    \"Active_in_FBA_Copy\": abs(solution.fluxes.get(rxn.id, 0.0)) > 1e-10,\n",
    "} for rxn in exchange_reactions])\n",
    "\n",
    "# Filter to only active exchange reactions and add 'Import' Column\n",
    "exchange_df_sub = (\n",
    "    exchange_df[exchange_df[\"Active_in_FBA_Copy\"] == True]\n",
    "    .assign(Import=lambda df: df[\"Flux\"].apply(lambda v: v < 0 if v != 0 else pd.NA))\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "# Filter the list to those reactions marked for inclusion\n",
    "exchange_df2 = exchange_df_full[exchange_df_full[\"Include\"] == True]\n",
    "\n",
    "# Merge the curated exchange list with Import info from FBA\n",
    "merged_df = exchange_df2.merge(\n",
    "    exchange_df_sub[[\"ID\", \"Import\"]],\n",
    "    on=\"ID\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Import modified exchange reactions incl directionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get IDs from final_exchanges_df\n",
    "allowed_ids = set(final_exchanges_df[\"ID\"])\n",
    "\n",
    "# Optional: Block all exchange reactions NOT in the list\n",
    "# for rxn in model_copy.exchanges:\n",
    "    # if rxn.id not in allowed_ids:\n",
    "        # rxn.lower_bound = 0.0\n",
    "        # rxn.upper_bound = 0.0\n",
    "\n",
    "# Handle Import = False and Import = True separately\n",
    "for _, row in final_exchanges_df.iterrows():\n",
    "    rxn_id = row[\"ID\"]\n",
    "    is_import = row[\"Import\"]\n",
    "\n",
    "    # Get the reaction from the model\n",
    "    rxn = model_copy.reactions.get_by_id(rxn_id)\n",
    "\n",
    "    if is_import is False:\n",
    "        rxn.lower_bound = 0.0\n",
    "\n",
    "    elif is_import is True:\n",
    "        prev_lower = rxn.lower_bound\n",
    "\n",
    "        # Create reversed reaction\n",
    "        reversed_rxn = Reaction(id=f\"{rxn.id}_reversed\")\n",
    "        reversed_rxn.name = f\"Reversed {rxn.name}\"\n",
    "        reversed_rxn.add_metabolites({met: -coef for met, coef in rxn.metabolites.items()})\n",
    "        reversed_rxn.lower_bound = 0.0\n",
    "        reversed_rxn.upper_bound = abs(prev_lower)\n",
    "\n",
    "        # Add the new reversed reaction to the model\n",
    "        model_copy.add_reactions([reversed_rxn])\n",
    "\n",
    "        # Find all groups that contain this reaction and update them\n",
    "        for group in model_copy.groups:\n",
    "            if rxn in group.members:\n",
    "                group.remove_members([rxn])\n",
    "                group.add_members([reversed_rxn])\n",
    "\n",
    "        # Remove the original reaction from the model\n",
    "        model_copy.remove_reactions([rxn])\n",
    "\n",
    "# Note: This version of model_copy restores the original FBA value of 0.314!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make export reactions also irreversible\n",
    "\n",
    "# Assume `model` is your cobra.Model and `reaction_ids` is your list of reaction IDs\n",
    "reaction_ids = ['EX_co2(e)', 'EX_h(e)', 'EX_h2o(e)']  # Replace with your actual reaction IDs\n",
    "\n",
    "for rxn_id in reaction_ids:\n",
    "    if rxn_id in model_copy.reactions:\n",
    "        model_copy.reactions.get_by_id(rxn_id).lower_bound = 0.0\n",
    "    else:\n",
    "        print(f\"Reaction {rxn_id} not found in model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a deep copy of the model to avoid modifying the original\n",
    "model_copy2 = copy.deepcopy(model_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rxn in model_copy2.reactions:\n",
    "    if rxn.id.endswith(\"_reversed\"):\n",
    "        if rxn.upper_bound == 0.0:\n",
    "            rxn.upper_bound = 2.0\n",
    "\n",
    "# Note: This version of model_copy exepectedly restores a higher FBA value of 0.644!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export as .mat for matlab applications\n",
    "\n",
    "save_matlab_model(model_copy2, raw_mat_path / \"iMS520_context.mat\") # use generic model to get unbiased couplings (filter later!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FASTCC model reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Luca/opt/anaconda3/envs/cobra_escher_env/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    }
   ],
   "source": [
    "# Reduce model with COBRApy FASTCC \n",
    "consistent_generic_model = fastcc(model_copy2)\n",
    "\n",
    "# Note: This version of model_copy reproduces the higher FBA value of 0.644!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stoichiometric Matrix Rank: 436\n",
      "Number of Reactions: 544\n",
      "Degrees of Freedom: 108\n"
     ]
    }
   ],
   "source": [
    "# Get the stoichiometric matrix as a NumPy array\n",
    "stoich_dense = create_stoichiometric_matrix(consistent_generic_model)  # Already a NumPy array\n",
    "\n",
    "# Compute the rank of the stoichiometric matrix\n",
    "rank = np.linalg.matrix_rank(stoich_dense)\n",
    "\n",
    "# Degrees of freedom\n",
    "num_reactions = len(consistent_generic_model.reactions)\n",
    "dof = num_reactions - rank\n",
    "\n",
    "# Output\n",
    "print(f\"Stoichiometric Matrix Rank: {rank}\")\n",
    "print(f\"Number of Reactions: {num_reactions}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sets of reaction IDs from both models\n",
    "original_rxns = set(r.id for r in model_copy.reactions)\n",
    "consistent_rxns = set(r.id for r in consistent_generic_model.reactions)\n",
    "\n",
    "# Find reactions that were removed\n",
    "removed_rxns = sorted(original_rxns - consistent_rxns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F2C2 Coupling Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Make F2C2 Data accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add reaction annotations to match F2C2 blocked reactions\n",
    "model_rxns = [rxn.id for rxn in model.reactions]\n",
    "F2C2_Blocked_Reactions_df.loc[len(F2C2_Blocked_Reactions_df)] = model_rxns\n",
    "\n",
    "# Identify unblocked reactions from the second row (index 1)\n",
    "unblocked_mask = F2C2_Blocked_Reactions_df.loc[0] == 0\n",
    "unblocked_reactions = F2C2_Blocked_Reactions_df.loc[1][unblocked_mask].tolist()\n",
    "\n",
    "# Update Coupled_Pairs_df index and columns with unblocked reactions\n",
    "Coupled_Pairs_df.index = unblocked_reactions\n",
    "Coupled_Pairs_df.columns = unblocked_reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dataframe for reactions in model\n",
    "\n",
    "model_rxns = set([rxn.id for rxn in consistent_generic_model.reactions])\n",
    "valid_rxns = Coupled_Pairs_df.index.intersection(model_rxns)\n",
    "Coupled_Pairs_df = Coupled_Pairs_df.loc[valid_rxns, valid_rxns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of how many fully coupled pairs\n",
    "fully_coupled_count = int(((Coupled_Pairs_df == 1).sum().sum()) - len(Coupled_Pairs_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*SideQuest* : Investigate difference in 'blocking' between FASTCC and F2C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and convert reactions from models to sets for fast comparison\n",
    "generic_rxns = {rxn.id for rxn in consistent_generic_model.reactions}\n",
    "f2c2_unblocked_rxns = set(unblocked_reactions)\n",
    "\n",
    "# Compare overlaps and differences\n",
    "overlap_generic = list(generic_rxns & f2c2_unblocked_rxns)\n",
    "\n",
    "# Reactions unblocked by F2C2 but removed by FASTCC\n",
    "missing_from_generic = list(f2c2_unblocked_rxns - generic_rxns)\n",
    "\n",
    "# Reactions kept by FASTCC but blocked by F2C2 (ideally empty)\n",
    "unexpected_in_generic = list(generic_rxns - f2c2_unblocked_rxns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Luca/opt/anaconda3/envs/cobra_escher_env/lib/python3.10/site-packages/cobra/core/group.py:147: UserWarning: need to pass in a list\n",
      "  warn(\"need to pass in a list\")\n"
     ]
    }
   ],
   "source": [
    "# Study on F2C2 Blocking - does this give a feasible solution?\n",
    "\n",
    "# Create a deep copy of the model F2C2 was run on \n",
    "F2C2_model = copy.deepcopy(model_copy)\n",
    "\n",
    "# Get the Reaction objects from the model\n",
    "reactions_to_remove = [F2C2_model.reactions.get_by_id(rid) for rid in unexpected_in_generic]\n",
    "\n",
    "# Remove them from the model\n",
    "F2C2_model.remove_reactions(reactions_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Solution infeasible at 0x1add49690>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Luca/opt/anaconda3/envs/cobra_escher_env/lib/python3.10/site-packages/cobra/util/solver.py:554: UserWarning: Solver status is 'infeasible'.\n",
      "  warn(f\"Solver status is '{status}'.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Not feasible \n",
    "solution = F2C2_model.optimize()\n",
    "# Print full solution object\n",
    "print(solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Implement Enzyme Subsets into model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 'EX_' reactions removed: 14\n",
      "'biomass_BIF' was removed: True\n",
      "'ATPM' was removed: True\n"
     ]
    }
   ],
   "source": [
    "# Get original reaction names \n",
    "original_reactions = list(Coupled_Pairs_df.index)\n",
    "\n",
    "# Identify reactions to remove\n",
    "ex_removed = [r for r in original_reactions if r.startswith(\"EX_\")]\n",
    "biomass_removed = \"biomass_BIF\" in original_reactions\n",
    "atpm_removed = \"ATPM\" in original_reactions\n",
    "\n",
    "# Combine into a single exclusion list\n",
    "reactions_to_remove = set(ex_removed)\n",
    "if biomass_removed:\n",
    "    reactions_to_remove.add(\"biomass_BIF\")\n",
    "if atpm_removed:\n",
    "    reactions_to_remove.add(\"ATPM\")\n",
    "\n",
    "# Filter the DataFrame\n",
    "filtered_reactions = [r for r in original_reactions if r not in reactions_to_remove]\n",
    "Coupled_Pairs_df_cleaned = Coupled_Pairs_df.loc[filtered_reactions, filtered_reactions]\n",
    "\n",
    "# Report\n",
    "print(f\"Total 'EX_' reactions removed: {len(ex_removed)}\")\n",
    "print(f\"'biomass_BIF' was removed: {biomass_removed}\")\n",
    "print(f\"'ATPM' was removed: {atpm_removed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a graph of fully coupled reactions\n",
    "G = nx.Graph()\n",
    "\n",
    "for row in Coupled_Pairs_df_cleaned.index:\n",
    "    for col in Coupled_Pairs_df_cleaned.columns:\n",
    "        if Coupled_Pairs_df_cleaned.loc[row, col] == 1 and row != col:\n",
    "            G.add_edge(row, col)\n",
    "\n",
    "# Find connected components (fully coupled groups)\n",
    "coupled_groups = list(nx.connected_components(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from reaction ID to COBRA group name\n",
    "reaction_to_group = {}\n",
    "\n",
    "for group in model.groups:\n",
    "    group_name = group.name\n",
    "    for member in group.members:\n",
    "        if hasattr(member, 'id'):  # make sure it's a Reaction, not a Metabolite or Gene\n",
    "            reaction_to_group[member.id] = group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine coupled groups with their annotated groups in the COBRA model and obtain in- and output of coupled groups\n",
    "\n",
    "combined_data = []\n",
    "\n",
    "for group in coupled_groups:\n",
    "    group_reactions = list(group)\n",
    "    \n",
    "    # COBRA Group Names\n",
    "    group_names = set()\n",
    "    for rxn in group_reactions:\n",
    "        if rxn in reaction_to_group:\n",
    "            group_names.add(reaction_to_group[rxn])\n",
    "    \n",
    "    # Net Stoichiometry\n",
    "    stoich = defaultdict(float)\n",
    "    for rxn_id in group_reactions:\n",
    "        rxn = model.reactions.get_by_id(rxn_id)\n",
    "        for met, coeff in rxn.metabolites.items():\n",
    "            stoich[met] += coeff\n",
    "\n",
    "    inputs = [met.id for met, coeff in stoich.items() if coeff < 0]\n",
    "    outputs = [met.id for met, coeff in stoich.items() if coeff > 0]\n",
    "\n",
    "    # Append Combined Info\n",
    "    combined_data.append({\n",
    "        \"Coupled_Reactions\": group_reactions,\n",
    "        \"COBRA_Groups\": list(group_names) if group_names else [\"Unassigned\"],\n",
    "        \"Num_Inputs\": len(inputs),\n",
    "        \"Num_Outputs\": len(outputs),\n",
    "        \"Input_Metabolites\": inputs,\n",
    "        \"Output_Metabolites\": outputs\n",
    "    })\n",
    "\n",
    "# Create the final DataFrame\n",
    "Fully_Coupled_df = pd.DataFrame(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the reactions per group form a single connected component (i.e., fully connected cluster)\n",
    "Fully_Coupled_df['Cluster'] = Fully_Coupled_df['Coupled_Reactions'].apply(\n",
    "    lambda rxn_list: are_reactions_interconnected(consistent_generic_model, rxn_list)\n",
    ")\n",
    "\n",
    "# Remove Entries that are not fully connected\n",
    "\n",
    "Fully_Coupled_df = Fully_Coupled_df[Fully_Coupled_df['Cluster'] != False]\n",
    "\n",
    "# Remove objective function (if in df)\n",
    "Fully_Coupled_df['Reactions'] = Fully_Coupled_df['Coupled_Reactions'].apply(lambda rxns: [r for r in rxns if r != objective_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Option 2*: Selective lumping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Coupled_Reactions','COBRA_Groups']\n",
    "\n",
    "Fully_Coupled_df_v2 =  Fully_Coupled_df[columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform lumping only excl. exchange reactions \n",
    "\n",
    "lumped_model_v2, lumping_log_v2 = lump_reaction(consistent_generic_model, coupled_df=Fully_Coupled_df_v2, verbose=False, label_type=\"Group\", Search_COBRA_groups=False)\n",
    "\n",
    "# Note: lumped_model_v2 can still carry flux and reproduce the FBA value 0.644!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_length = Fully_Coupled_df_v2['Coupled_Reactions'].apply(len).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All pseudo-reactions validated — they can carry flux.\n"
     ]
    }
   ],
   "source": [
    "# Get all pseudo-reaction IDs\n",
    "pseudo_reactions = [rxn.id for rxn in lumped_model_v2.reactions if rxn.id.startswith(\"Pseudo_\")]\n",
    "\n",
    "# Use Flux Variability Analysis to test max possible flux\n",
    "# fraction_of_optimum=0.0 tells FVA to ignore the model's objective and simply check whether each reaction can carry any flux under the current constraints.\n",
    "fva_results = flux_variability_analysis(lumped_model_v2, reaction_list=pseudo_reactions, fraction_of_optimum=0.0) \n",
    "\n",
    "# Identify if any pseudoreactions are blocked (min=max=0)\n",
    "fva_results['is_blocked'] = (fva_results['minimum'].abs() < 1e-6) & (fva_results['maximum'].abs() < 1e-6)\n",
    "\n",
    "# Check if any reactions are blocked\n",
    "if not fva_results['is_blocked'].any():\n",
    "    print(\"✅ All pseudo-reactions validated — they can carry flux.\")\n",
    "else:\n",
    "    print(\"❌ Some pseudo-reactions are blocked and cannot carry flux:\")\n",
    "    blocked = fva_results[fva_results['is_blocked']]\n",
    "    print(blocked[['minimum', 'maximum']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stoichiometric Matrix Rank: 430\n",
      "Number of Reactions: 516\n",
      "Degrees of Freedom: 86\n"
     ]
    }
   ],
   "source": [
    "# Get the stoichiometric matrix as a NumPy array\n",
    "stoich_dense = create_stoichiometric_matrix(lumped_model_v2)  # Already a NumPy array\n",
    "\n",
    "# Compute the rank of the stoichiometric matrix\n",
    "rank = np.linalg.matrix_rank(stoich_dense)\n",
    "\n",
    "# Degrees of freedom\n",
    "num_reactions = len(lumped_model_v2.reactions)\n",
    "dof = num_reactions - rank\n",
    "\n",
    "# Output\n",
    "print(f\"Stoichiometric Matrix Rank: {rank}\")\n",
    "print(f\"Number of Reactions: {num_reactions}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module-oriented Reaction Lumping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Group Sanity Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping for all groups and their corresponding reactions\n",
    "\n",
    "# Extract groups and their reactions\n",
    "group_mapping_data = [\n",
    "    {\n",
    "        'COBRA_Group': group.name,\n",
    "        'Reactions': [member.id for member in group.members if member.__class__.__name__ == 'Reaction']\n",
    "    }\n",
    "    for group in lumped_model_v2.groups\n",
    "    if any(member.__class__.__name__ == 'Reaction' for member in group.members)\n",
    "]\n",
    "Raw_Group_df = pd.DataFrame(group_mapping_data)\n",
    "\n",
    "# Normalize group names (case + spacing)\n",
    "Raw_Group_df['Normalized_Group'] = Raw_Group_df['COBRA_Group'].apply(\n",
    "    lambda x: ' '.join(x.strip().split()).title()\n",
    ")\n",
    "\n",
    "# Group by normalized name, merge reactions, remove duplicates\n",
    "Normalized_Group_df = (\n",
    "    Raw_Group_df.groupby('Normalized_Group')\n",
    "    .agg({'Reactions': lambda lists: list(set(r for sub in lists for r in sub))})\n",
    "    .reset_index()\n",
    "    .rename(columns={'Normalized_Group': 'COBRA_Group'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect suspiciously similar group names using fuzzy matching\n",
    "\n",
    "group_names = Normalized_Group_df['COBRA_Group'].tolist()\n",
    "suspicious_matches = []\n",
    "SIMILARITY_THRESHOLD = 85 # max.: 100 \n",
    "\n",
    "for i, name1 in enumerate(group_names):\n",
    "    for j, name2 in enumerate(group_names):\n",
    "        if i >= j:\n",
    "            continue\n",
    "        score = fuzz.ratio(name1, name2)\n",
    "        if score >= SIMILARITY_THRESHOLD and name1 != name2:\n",
    "            suspicious_matches.append({\n",
    "                'Group_1': name1,\n",
    "                'Group_2': name2,\n",
    "                'Similarity_Score': score\n",
    "            })\n",
    "\n",
    "# Build suspicious match DataFrame and default merge plan\n",
    "suspicious_df = pd.DataFrame(suspicious_matches)\n",
    "suspicious_df['Merge_Into'] = suspicious_df['Group_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Check of suspicious match DataFrame + check of merge names\n",
    "\n",
    "suspicious_df.loc[suspicious_df['Group_1'] == 'Pentose Phosphate Pathwa', 'Merge_Into'] = 'Pentose Phosphate Pathway'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping from each group name to its cleaned (merged) name\n",
    "merge_map = {}\n",
    "\n",
    "for _, row in suspicious_df.iterrows():\n",
    "    merge_map[row['Group_1']] = row['Merge_Into']\n",
    "    merge_map[row['Group_2']] = row['Merge_Into']\n",
    "\n",
    "# Apply merge mapping to normalized group names\n",
    "Normalized_Group_df['Final_Group'] = Normalized_Group_df['COBRA_Group'].apply(\n",
    "    lambda g: merge_map.get(g, g)\n",
    ")\n",
    "\n",
    "# Re-merge by Final_Group, removing duplicates in reaction lists\n",
    "Final_Group_df = (\n",
    "    Normalized_Group_df.groupby('Final_Group')\n",
    "    .agg({'Reactions': lambda lists: list(set(r for sub in lists for r in sub))})\n",
    "    .reset_index()\n",
    "    .rename(columns={'Final_Group': 'COBRA_Group'})\n",
    ")\n",
    "\n",
    "# Add a column for the number of reactions per group\n",
    "Final_Group_df['Reaction_Count'] = Final_Group_df['Reactions'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the reactions per group form a single connected component (i.e., fully connected cluster)\n",
    "Final_Group_df['Cluster'] = Final_Group_df['Reactions'].apply(\n",
    "    lambda rxn_list: are_reactions_interconnected(lumped_model_v2, rxn_list)\n",
    ")\n",
    "\n",
    "# Remove Entries that are not fully connected\n",
    "\n",
    "Final_Group_df = Final_Group_df[Final_Group_df['Cluster'] != False]\n",
    "\n",
    "# Remove objective function (if in df)\n",
    "Final_Group_df['Reactions'] = Final_Group_df['Reactions'].apply(lambda rxns: [r for r in rxns if r != objective_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Decide which groups to merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Modules = Final_Group_df['COBRA_Group'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export for manual investigation\n",
    "\n",
    "Final_Group_df.to_csv(raw_csv_path / 'iMS520_context_lumpmodule.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define modules that should be left intact (no lumping)\n",
    "\n",
    "avoid_list = [\n",
    " 'Anaplerotic Reactions',\n",
    " 'Citrate Acid Cycle',\n",
    " 'Energy Metabolism',\n",
    " 'Fructose And Mannose Metabolism',\n",
    " 'Glycogen Metabolism',\n",
    " 'Glycolysis',\n",
    " 'Glycolysis / Gluconeogenesis',\n",
    " 'Other',\n",
    " 'Oxidative Phosphorylation',\n",
    " 'Pentose And Glucoronate Interconversions',\n",
    " 'Pyruvate Metabolism',\n",
    " 'Starch Sucrose Metabolism',\n",
    " 'Starch Sucrose Metabolismgalactose Metabolism',\n",
    " 'Unassigned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter & deduplicate rows in the avoid_list\n",
    "avoid_reactions_series = Final_Group_df[Final_Group_df['COBRA_Group'].isin(avoid_list)]['Reactions']\n",
    "\n",
    "avoid_reactions = set()\n",
    "for reaction_list in avoid_reactions_series:\n",
    "    avoid_reactions.update(reaction_list)\n",
    "\n",
    "# Make a deep copy of the DataFrame to avoid changing the original\n",
    "Lump_df = Final_Group_df.copy(deep=True)\n",
    "\n",
    "# Iterate over rows not in avoid_list and clean their Reactions\n",
    "for idx, row in Lump_df.iterrows():\n",
    "    if row['COBRA_Group'] not in avoid_list:\n",
    "        original_reactions = set(row['Reactions'])\n",
    "        updated_reactions = original_reactions - avoid_reactions\n",
    "\n",
    "        if original_reactions != updated_reactions:\n",
    "            removed = original_reactions & avoid_reactions\n",
    "            # print(f\"Cleaning group '{row['COBRA_Group']}': removed {len(removed)} reaction(s): {removed}\")\n",
    "\n",
    "        Lump_df.at[idx, 'Reactions'] = list(updated_reactions)\n",
    "\n",
    "# Identify rows where 'Reactions' is an empty list\n",
    "empty_rows = Lump_df[Lump_df['Reactions'].apply(lambda x: len(x) == 0)]\n",
    "\n",
    "# Remove these rows from the cleaned DataFrame\n",
    "Final_Lump_df = Lump_df[Lump_df['Reactions'].apply(lambda x: len(x) > 1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the reactions per group form a single connected component (i.e., fully connected cluster)\n",
    "Final_Lump_df['Cluster_New'] = Final_Lump_df['Reactions'].apply(\n",
    "    lambda rxn_list: are_reactions_interconnected(lumped_model_v2, rxn_list))\n",
    "\n",
    "# Remove Entries that are not fully connected\n",
    "\n",
    "Final_Lump_df = Final_Lump_df[Final_Lump_df['Cluster'] != False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Lump modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where 'COBRA_Group' is in the avoid_list\n",
    "Filtered_Lump_df = Final_Lump_df[~Final_Lump_df['COBRA_Group'].isin(avoid_list)].copy() # these won't get lumped!\n",
    "\n",
    "#  Deduplicate reactions across all rows (ensures each reaction appears only once)\n",
    "seen_reactions = set()\n",
    "for idx, row in Filtered_Lump_df.iterrows():\n",
    "    unique_reactions = [rxn for rxn in row['Reactions'] if rxn not in seen_reactions]\n",
    "    seen_reactions.update(unique_reactions)\n",
    "    Filtered_Lump_df.at[idx, 'Reactions'] = unique_reactions\n",
    "\n",
    "# Remove reactions that start with \"EX_\"\n",
    "for idx, row in Filtered_Lump_df.iterrows():\n",
    "    non_exchange_reactions = [rxn for rxn in row['Reactions'] if not rxn.startswith(\"EX_\")]\n",
    "    Filtered_Lump_df.at[idx, 'Reactions'] = non_exchange_reactions\n",
    "\n",
    "# Remove rows with empty reaction lists\n",
    "Filtered_Lump_df = Filtered_Lump_df[Filtered_Lump_df['Reactions'].apply(len) > 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform lumping only excl. exchange reactions \n",
    "\n",
    "lumped_model_final, lump_log_final = lump_reaction(lumped_model_v2, coupled_df=Filtered_Lump_df, verbose=False, Search_COBRA_groups=True, label_type=\"Module\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4**: Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All pseudo-reactions validated — they can carry flux.\n"
     ]
    }
   ],
   "source": [
    "# Get all pseudo-reaction IDs\n",
    "pseudo_reactions = [rxn.id for rxn in lumped_model_final.reactions if rxn.id.startswith(\"Pseudo_\")]\n",
    "\n",
    "# Use Flux Variability Analysis to test max possible flux\n",
    "# fraction_of_optimum=0.0 tells FVA to ignore the model's objective and simply check whether each reaction can carry any flux under the current constraints.\n",
    "fva_results = flux_variability_analysis(lumped_model_final, reaction_list=pseudo_reactions, fraction_of_optimum=0.0) \n",
    "\n",
    "# Identify if any pseudoreactions are blocked (min=max=0)\n",
    "fva_results['is_blocked'] = (fva_results['minimum'].abs() < 1e-6) & (fva_results['maximum'].abs() < 1e-6)\n",
    "\n",
    "# Check if any reactions are blocked\n",
    "if not fva_results['is_blocked'].any():\n",
    "    print(\"✅ All pseudo-reactions validated — they can carry flux.\")\n",
    "else:\n",
    "    print(\"❌ Some pseudo-reactions are blocked and cannot carry flux:\")\n",
    "    blocked = fva_results[fva_results['is_blocked']]\n",
    "    print(blocked[['minimum', 'maximum']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stoichiometric Matrix Rank: 207\n",
      "Number of Reactions: 225\n",
      "Degrees of Freedom: 18\n"
     ]
    }
   ],
   "source": [
    "# Get the stoichiometric matrix as a NumPy array\n",
    "stoich_dense = create_stoichiometric_matrix(lumped_model_final)  # Already a NumPy array\n",
    "\n",
    "# Compute the rank of the stoichiometric matrix\n",
    "rank = np.linalg.matrix_rank(stoich_dense)\n",
    "\n",
    "# Degrees of freedom\n",
    "num_reactions = len(lumped_model_final.reactions)\n",
    "dof = num_reactions - rank\n",
    "\n",
    "# Output\n",
    "print(f\"Stoichiometric Matrix Rank: {rank}\")\n",
    "print(f\"Number of Reactions: {num_reactions}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_sbml_model(lumped_model_final, processed_sbml_path / 'iMS520_red1_context.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Carb Lists\n",
    "\n",
    "carb_list = ['EX_glc-D(e)_reversed','EX_fru(e)_reversed','EX_sucr(e)_reversed','EX_arab-L(e)_reversed']\n",
    "carb_list_original = ['EX_glc-D(e)','EX_fru(e)','EX_sucr(e)','EX_arab-L(e)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassign original flux bounds\n",
    "\n",
    "daughter_model = copy.deepcopy(lumped_model_final)\n",
    "\n",
    "# Store original bounds as a dictionary: {reaction_id: (lower_bound, upper_bound)}\n",
    "original_bounds = {\n",
    "    rxn.id: (rxn.lower_bound, rxn.upper_bound)\n",
    "    for rxn in model_copy.reactions\n",
    "}\n",
    "\n",
    "# Apply the original bounds to the target model\n",
    "for rxn_id, (lb, ub) in original_bounds.items():\n",
    "    if rxn_id in daughter_model.reactions:\n",
    "        rxn = daughter_model.reactions.get_by_id(rxn_id)\n",
    "        rxn.lower_bound = lb\n",
    "        rxn.upper_bound = ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run analysis for both models\n",
    "results_original, flux_activity_original, filtered_flux_original = analyze_model(model, 'Original',carb_list_original)\n",
    "results_mod_original, flux_activity_mod_original, filtered_flux_mod_original = analyze_model(model_copy, 'Original_Rev',carb_list,Direction=\"Reversed\")\n",
    "results_mod_original_FB, flux_activity_mod_original_FB, filtered_flux_mod_original_FB = analyze_model(model_copy2, 'Original_Rev_FB',carb_list,Direction=\"Reversed\")\n",
    "results_fastcc, flux_activity_fastcc, filtered_flux_fastcc = analyze_model(consistent_generic_model, 'FASTCC',carb_list,Direction=\"Reversed\")\n",
    "results_final, flux_activity_final, filtered_flux_final = analyze_model(lumped_model_final, 'Final_Red',carb_list,Direction=\"Reversed\")\n",
    "results_daugther, flux_activity_daughter, filtered_flux_daughter = analyze_model(daughter_model, 'daugther',carb_list,Direction=\"Reversed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Objective_comparison_df = pd.concat([results_original,results_daugther], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Objective_comparison_df.to_csv(raw_csv_path / 'iMS520_context_FBA_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_sbml_model(daughter_model, processed_sbml_path / 'iMS520_red2_context.xml') # this one works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel = read_sbml_model(processed_sbml_path / 'iMS520_red2_context.xml') # this one does not work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cobra_escher_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
